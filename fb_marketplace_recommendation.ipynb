{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fb_marketplace_recommendation",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Facebook marketplace recommendation\n",
        "\n",
        "This notbook shows the result of the repo https://github.com/chrisyw0/fb_marketplace_recommendation\n",
        "\n",
        "Assuming the product and images datasets (in pickle file format), and image zip file have been saved in the google drive. \n",
        "\n",
        "For more detailed instruction, please check the README file in the repo. "
      ],
      "metadata": {
        "id": "a71B43yyRAWO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount Google Drive and copy required files into this notebook"
      ],
      "metadata": {
        "id": "9iVWeEp0REAm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2VtqZg8fNY1",
        "outputId": "33b23414-8221-4712-f007-b25d82462764"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!rm -rf ./fb_marketplace_recommendation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDZyvIbnsgt_",
        "outputId": "e19d4407-f9d8-488e-f975-d4992dd45b64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/chrisyw0/fb_marketplace_recommendation.git ./fb_marketplace_recommendation\n",
        "%cd ./fb_marketplace_recommendation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uGMXuC_fWhI",
        "outputId": "e29c3735-bf63-4d7c-f948-332e0eb89121"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into './fb_marketplace_recommendation'...\n",
            "remote: Enumerating objects: 165, done.\u001b[K\n",
            "remote: Counting objects: 100% (165/165), done.\u001b[K\n",
            "remote: Compressing objects: 100% (117/117), done.\u001b[K\n",
            "remote: Total 165 (delta 99), reused 95 (delta 46), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (165/165), 349.26 KiB | 3.09 MiB/s, done.\n",
            "Resolving deltas: 100% (99/99), done.\n",
            "/content/fb_marketplace_recommendation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data\n",
        "!cp /content/drive/MyDrive/FB_marketplace/data/product.pkl ./data/product.pkl\n",
        "!cp /content/drive/MyDrive/FB_marketplace/data/image.pkl ./data/image.pkl\n",
        "!cp /content/drive/MyDrive/FB_marketplace/data/product_clean.pkl ./data/product_clean.pkl\n",
        "!cp /content/drive/MyDrive/FB_marketplace/data/image_clean.pkl ./data/image_clean.pkl"
      ],
      "metadata": {
        "id": "bN49UjjKfYeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/FB_marketplace/data/images_fb.zip ./data/images_fb.zip"
      ],
      "metadata": {
        "id": "ry_GiAPsSsR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq ./data/images_fb.zip -d ./data/"
      ],
      "metadata": {
        "id": "Xdfw2uq-S_ip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install required packages"
      ],
      "metadata": {
        "id": "8T4jevfJRvmW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install geopandas\n",
        "!pip install --upgrade gensim\n",
        "!pip install --upgrade tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecgb5INeoOA4",
        "outputId": "0c7cf0e7-ba56-4512-fcf3-b277e4f89283"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting geopandas\n",
            "  Downloading geopandas-0.10.2-py2.py3-none-any.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.25.0 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.3.5)\n",
            "Collecting pyproj>=2.2.0\n",
            "  Downloading pyproj-3.2.1-cp37-cp37m-manylinux2010_x86_64.whl (6.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.3 MB 37.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: shapely>=1.6 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.8.1.post1)\n",
            "Collecting fiona>=1.8\n",
            "  Downloading Fiona-1.8.21-cp37-cp37m-manylinux2014_x86_64.whl (16.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 16.7 MB 384 kB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (21.4.0)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (7.1.2)\n",
            "Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (57.4.0)\n",
            "Collecting click-plugins>=1.0\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Collecting cligj>=0.5\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (2021.10.8)\n",
            "Collecting munch\n",
            "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (2.8.2)\n",
            "Installing collected packages: munch, cligj, click-plugins, pyproj, fiona, geopandas\n",
            "Successfully installed click-plugins-1.1.1 cligj-0.7.2 fiona-1.8.21 geopandas-0.10.2 munch-2.5.0 pyproj-3.2.1\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Collecting gensim\n",
            "  Downloading gensim-4.1.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.1 MB 65.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.6)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Installing collected packages: gensim\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-4.1.2\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.44.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.24.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (13.0.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
            "Installing collected packages: tf-estimator-nightly\n",
            "Successfully installed tf-estimator-nightly-2.8.0.dev2021122109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py"
      ],
      "metadata": {
        "id": "9QHiGPdQMdzv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d16c53d-0a95-4523-b777-6ce3f0db5f85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Try reloading from cached file for product and image dataframe\n",
            "Load data success, tabular data shape (8091, 9), image data shape (12604, 5)\n",
            "Images data already existed\n",
            "Reload from ./data/image_clean.pkl for clean image dataframe\n",
            "Clean data success, new shape (11128, 10)\n",
            "                                     id  ... image_mode\n",
            "0  912bb259-3ad9-457b-9db1-ce1da9016057  ...        RGB\n",
            "1  b166d305-b852-4bdd-83f4-465b20da94fa  ...        RGB\n",
            "2  68f5a29d-0075-4d60-81c1-ab684a82e50c  ...        RGB\n",
            "3  f6a309d7-d247-446a-9b5e-aceefdd4334d  ...        RGB\n",
            "4  2c2b3a6f-15b3-4289-937a-15482d9f5781  ...        RGB\n",
            "\n",
            "[5 rows x 10 columns]\n",
            "Reload from ./data/product_clean.pkl for clean product dataframe\n",
            "Clean data success, new shape (6902, 22)\n",
            "                                     id  ...                  lon\n",
            "1  243809c0-9cfc-4486-ad12-3b7a16605ba9  ...  -1.0318729593399247\n",
            "2  1c58d3f9-8b93-47ea-9415-204fcc2a22e6  ...            -4.225739\n",
            "3  860673f1-57f6-47ba-8d2f-13f9e05b8f9a  ...  0.32909339328596654\n",
            "4  59948726-29be-4b35-ade5-bb2fd7331856  ...           -2.4476231\n",
            "5  16dbc860-696e-4cda-93f6-4dd4926573fb  ...            -2.026164\n",
            "\n",
            "[5 rows x 22 columns]\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 800x800 with 1 Axes>\n",
            "        image_width  ...   image_ratio\n",
            "count  11128.000000  ...  11128.000000\n",
            "mean     804.659597  ...      0.945865\n",
            "std      170.810798  ...      0.273763\n",
            "min      155.000000  ...      0.500000\n",
            "25%      736.750000  ...      0.750000\n",
            "50%      768.000000  ...      0.750000\n",
            "75%     1024.000000  ...      1.333333\n",
            "max     1024.000000  ...      1.500000\n",
            "\n",
            "[8 rows x 3 columns]\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 640x480 with 4 Axes>\n",
            "Linear Regression Result:\n",
            "========================================\n",
            "Coef: [139.02714798 225.56543063  13.09849676 -10.4954614  -18.73582537\n",
            " -65.64617674 -24.37482656  91.17844257 -35.58303102   8.34879788\n",
            "   8.83292528 -78.462138    61.16996268 -12.54085304 118.22410123\n",
            "  28.99837266  27.30790182]\n",
            "Interception: 71.09811782031943\n",
            "RMSE: 170.28221400570627\n",
            "========================================\n",
            "tcmalloc: large alloc 3194265600 bytes == 0x564f5aef0000 @  0x7f41755b11e7 0x7f4172bc00ce 0x7f4172c16cf5 0x7f4172c16f4f 0x7f4172cb9673 0x564e3299611c 0x564e32995ef0 0x564e32a0a64d 0x564e32a04a2e 0x564e3299788a 0x564e32a06719 0x564e32a04a2e 0x564e3299788a 0x564e32a06719 0x564e32a04a2e 0x564e3299788a 0x564e32a09d30 0x564e329977aa 0x564e32a05b4f 0x564e329977aa 0x564e32a058f6 0x564e32a04a2e 0x564e32a04723 0x564e32ace812 0x564e32aceb8d 0x564e32acea36 0x564e32aa6183 0x564e32aa5e2c 0x7f417439bc87 0x564e32aa5d0a\n",
            "tcmalloc: large alloc 3194265600 bytes == 0x565059500000 @  0x7f41755b11e7 0x7f4172bc00ce 0x7f4172c1a726 0x7f4172c1ab09 0x7f4172c1c620 0x7f4172c1cd1b 0x7f4172cbe41b 0x564e3299611c 0x564e32995ef0 0x564e32a0a64d 0x564e32a04cdd 0x564e328d6e2b 0x564e32a06ff1 0x564e32a04a2e 0x564e3299788a 0x564e32a06719 0x564e32a04a2e 0x564e3299788a 0x564e32a05b4f 0x564e32a04a2e 0x564e32997f21 0x564e32998341 0x564e32a06ff1 0x564e32a04a2e 0x564e3299788a 0x564e32a05b4f 0x564e329977aa 0x564e32a05b4f 0x564e329977aa 0x564e32a058f6 0x564e32a04a2e\n",
            "tcmalloc: large alloc 3194265600 bytes == 0x565059500000 @  0x7f41755b11e7 0x7f4172bc00ce 0x7f4172c1a726 0x7f4172c1ab09 0x7f4172c1c620 0x7f4172c1cd1b 0x7f4172cbe41b 0x564e3299611c 0x564e32995ef0 0x564e32a0a64d 0x564e32a04cdd 0x564e328d6e2b 0x564e32a06ff1 0x564e32a04a2e 0x564e3299788a 0x564e32a06719 0x564e329977aa 0x564e32a05b4f 0x564e32a04a2e 0x564e3299788a 0x564e32a05b4f 0x564e329977aa 0x564e32a05b4f 0x564e329977aa 0x564e32a058f6 0x564e32a04a2e 0x564e32a04723 0x564e32ace812 0x564e32aceb8d 0x564e32acea36 0x564e32aa6183\n",
            "tcmalloc: large alloc 3194265600 bytes == 0x564f5aef0000 @  0x7f41755b11e7 0x7f4172bc00ce 0x7f4172c1a726 0x7f4172c0d475 0x7f4172cbe3c7 0x564e3299611c 0x564e32995ef0 0x564e32a0a64d 0x564e32a04cdd 0x564e3299788a 0x564e32a06719 0x564e32a04cdd 0x564e328d6e2b 0x564e32a06ff1 0x564e32a04a2e 0x564e3299788a 0x564e32a06719 0x564e32a04cdd 0x564e3299788a 0x564e32a05b4f 0x564e329977aa 0x564e32a05b4f 0x564e329977aa 0x564e32a058f6 0x564e32a04a2e 0x564e32a04723 0x564e32ace812 0x564e32aceb8d 0x564e32acea36 0x564e32aa6183 0x564e32aa5e2c\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "Logistic Regression Result:\n",
            "========================================\n",
            "Coef: [[-0.01399157 -0.02433827 -0.00329919 ... -0.00837498 -0.00656847\n",
            "  -0.00416039]\n",
            " [-0.07868215 -0.07354476  0.00247005 ...  0.00048478  0.00215161\n",
            "   0.00194473]\n",
            " [-0.00076407  0.01741754 -0.00214697 ...  0.00305595  0.00086273\n",
            "  -0.00054879]\n",
            " ...\n",
            " [-0.01826218  0.00835133  0.0090351  ... -0.00793322 -0.00643632\n",
            "  -0.00398639]\n",
            " [-0.00069457 -0.01253153 -0.0011524  ...  0.00388425  0.00434404\n",
            "   0.00641932]\n",
            " [ 0.07773272  0.10061531 -0.00402184 ...  0.00451085  0.00718419\n",
            "   0.00722228]]\n",
            "Interception: [-0.02179961 -0.03847726 -0.01833557  0.12877898 -0.05377419 -0.00350835\n",
            " -0.08883004  0.01021826 -0.03733043  0.01334907 -0.00197639  0.00520435\n",
            "  0.10648116]\n",
            "                                  precision    recall  f1-score   support\n",
            "\n",
            "                      Appliances       0.09      0.08      0.09       173\n",
            "               Baby & Kids Stuff       0.14      0.13      0.14       127\n",
            " Clothes, Footwear & Accessories       0.11      0.10      0.11       143\n",
            "            Computers & Software       0.14      0.13      0.14       186\n",
            "           DIY Tools & Materials       0.11      0.10      0.11       172\n",
            "                 Health & Beauty       0.16      0.16      0.16       178\n",
            "                   Home & Garden       0.16      0.20      0.18       240\n",
            "     Music, Films, Books & Games       0.18      0.22      0.20       183\n",
            "    Office Furniture & Equipment       0.21      0.23      0.22       197\n",
            "                     Other Goods       0.04      0.05      0.04       133\n",
            "Phones, Mobile Phones & Telecoms       0.14      0.10      0.12       144\n",
            "        Sports, Leisure & Travel       0.08      0.08      0.08       133\n",
            "          Video Games & Consoles       0.06      0.05      0.06       131\n",
            "\n",
            "                        accuracy                           0.14      2140\n",
            "                       macro avg       0.13      0.13      0.13      2140\n",
            "                    weighted avg       0.13      0.14      0.13      2140\n",
            "\n",
            "========================================\n",
            "Training data path = /tmp/tmpta_qzqed\n",
            "Validation data path = /tmp/tmpda5g9tqe\n",
            "Testing data path = /tmp/tmpoxhd009p\n",
            "Found 6418 files belonging to 13 classes.\n",
            "2022-04-23 16:19:26.299149: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "Found 2140 files belonging to 13 classes.\n",
            "Found 2140 files belonging to 13 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94674944/94668760 [==============================] - 2s 0us/step\n",
            "94683136/94668760 [==============================] - 2s 0us/step\n",
            "Model: \"resnet50v2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)      (None, 262, 262, 3)  0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)            (None, 128, 128, 64  9472        ['conv1_pad[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)      (None, 130, 130, 64  0           ['conv1_conv[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)      (None, 64, 64, 64)   0           ['pool1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv2_block1_preact_bn (BatchN  (None, 64, 64, 64)  256         ['pool1_pool[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2_block1_preact_relu (Acti  (None, 64, 64, 64)  0           ['conv2_block1_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 64, 64, 64)   4096        ['conv2_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_pad (ZeroPaddin  (None, 66, 66, 64)  0           ['conv2_block1_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 64, 64, 64)   36864       ['conv2_block1_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2D)   (None, 64, 64, 256)  16640       ['conv2_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2D)   (None, 64, 64, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_out (Add)         (None, 64, 64, 256)  0           ['conv2_block1_0_conv[0][0]',    \n",
            "                                                                  'conv2_block1_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_preact_bn (BatchN  (None, 64, 64, 256)  1024       ['conv2_block1_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2_block2_preact_relu (Acti  (None, 64, 64, 256)  0          ['conv2_block2_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 64, 64, 64)   16384       ['conv2_block2_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_pad (ZeroPaddin  (None, 66, 66, 64)  0           ['conv2_block2_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 64, 64, 64)   36864       ['conv2_block2_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2D)   (None, 64, 64, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_out (Add)         (None, 64, 64, 256)  0           ['conv2_block1_out[0][0]',       \n",
            "                                                                  'conv2_block2_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_preact_bn (BatchN  (None, 64, 64, 256)  1024       ['conv2_block2_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2_block3_preact_relu (Acti  (None, 64, 64, 256)  0          ['conv2_block3_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 64, 64, 64)   16384       ['conv2_block3_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_pad (ZeroPaddin  (None, 66, 66, 64)  0           ['conv2_block3_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 32, 32, 64)   36864       ['conv2_block3_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNormal  (None, 32, 32, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activatio  (None, 32, 32, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 32, 32, 256)  0           ['conv2_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2D)   (None, 32, 32, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_out (Add)         (None, 32, 32, 256)  0           ['max_pooling2d[0][0]',          \n",
            "                                                                  'conv2_block3_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_preact_bn (BatchN  (None, 32, 32, 256)  1024       ['conv2_block3_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block1_preact_relu (Acti  (None, 32, 32, 256)  0          ['conv3_block1_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 32, 32, 128)  32768       ['conv3_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_pad (ZeroPaddin  (None, 34, 34, 128)  0          ['conv3_block1_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 32, 32, 128)  147456      ['conv3_block1_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2D)   (None, 32, 32, 512)  131584      ['conv3_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2D)   (None, 32, 32, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_out (Add)         (None, 32, 32, 512)  0           ['conv3_block1_0_conv[0][0]',    \n",
            "                                                                  'conv3_block1_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_preact_bn (BatchN  (None, 32, 32, 512)  2048       ['conv3_block1_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block2_preact_relu (Acti  (None, 32, 32, 512)  0          ['conv3_block2_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 32, 32, 128)  65536       ['conv3_block2_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_pad (ZeroPaddin  (None, 34, 34, 128)  0          ['conv3_block2_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 32, 32, 128)  147456      ['conv3_block2_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2D)   (None, 32, 32, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_out (Add)         (None, 32, 32, 512)  0           ['conv3_block1_out[0][0]',       \n",
            "                                                                  'conv3_block2_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_preact_bn (BatchN  (None, 32, 32, 512)  2048       ['conv3_block2_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block3_preact_relu (Acti  (None, 32, 32, 512)  0          ['conv3_block3_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 32, 32, 128)  65536       ['conv3_block3_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_pad (ZeroPaddin  (None, 34, 34, 128)  0          ['conv3_block3_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 32, 32, 128)  147456      ['conv3_block3_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2D)   (None, 32, 32, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_out (Add)         (None, 32, 32, 512)  0           ['conv3_block2_out[0][0]',       \n",
            "                                                                  'conv3_block3_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_preact_bn (BatchN  (None, 32, 32, 512)  2048       ['conv3_block3_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block4_preact_relu (Acti  (None, 32, 32, 512)  0          ['conv3_block4_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 32, 32, 128)  65536       ['conv3_block4_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_pad (ZeroPaddin  (None, 34, 34, 128)  0          ['conv3_block4_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 16, 16, 128)  147456      ['conv3_block4_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activatio  (None, 16, 16, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 512)  0          ['conv3_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2D)   (None, 16, 16, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_out (Add)         (None, 16, 16, 512)  0           ['max_pooling2d_1[0][0]',        \n",
            "                                                                  'conv3_block4_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_preact_bn (BatchN  (None, 16, 16, 512)  2048       ['conv3_block4_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block1_preact_relu (Acti  (None, 16, 16, 512)  0          ['conv4_block1_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 16, 16, 256)  131072      ['conv4_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_pad (ZeroPaddin  (None, 18, 18, 256)  0          ['conv4_block1_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 16, 16, 256)  589824      ['conv4_block1_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2D)   (None, 16, 16, 1024  525312      ['conv4_block1_preact_relu[0][0]'\n",
            "                                )                                ]                                \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_out (Add)         (None, 16, 16, 1024  0           ['conv4_block1_0_conv[0][0]',    \n",
            "                                )                                 'conv4_block1_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_preact_bn (BatchN  (None, 16, 16, 1024  4096       ['conv4_block1_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_preact_relu (Acti  (None, 16, 16, 1024  0          ['conv4_block2_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 16, 16, 256)  262144      ['conv4_block2_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_pad (ZeroPaddin  (None, 18, 18, 256)  0          ['conv4_block2_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 16, 16, 256)  589824      ['conv4_block2_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_out (Add)         (None, 16, 16, 1024  0           ['conv4_block1_out[0][0]',       \n",
            "                                )                                 'conv4_block2_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_preact_bn (BatchN  (None, 16, 16, 1024  4096       ['conv4_block2_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_preact_relu (Acti  (None, 16, 16, 1024  0          ['conv4_block3_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 16, 16, 256)  262144      ['conv4_block3_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_pad (ZeroPaddin  (None, 18, 18, 256)  0          ['conv4_block3_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 16, 16, 256)  589824      ['conv4_block3_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_out (Add)         (None, 16, 16, 1024  0           ['conv4_block2_out[0][0]',       \n",
            "                                )                                 'conv4_block3_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_preact_bn (BatchN  (None, 16, 16, 1024  4096       ['conv4_block3_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_preact_relu (Acti  (None, 16, 16, 1024  0          ['conv4_block4_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 16, 16, 256)  262144      ['conv4_block4_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_pad (ZeroPaddin  (None, 18, 18, 256)  0          ['conv4_block4_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 16, 16, 256)  589824      ['conv4_block4_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_out (Add)         (None, 16, 16, 1024  0           ['conv4_block3_out[0][0]',       \n",
            "                                )                                 'conv4_block4_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_preact_bn (BatchN  (None, 16, 16, 1024  4096       ['conv4_block4_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_preact_relu (Acti  (None, 16, 16, 1024  0          ['conv4_block5_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 16, 16, 256)  262144      ['conv4_block5_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_pad (ZeroPaddin  (None, 18, 18, 256)  0          ['conv4_block5_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 16, 16, 256)  589824      ['conv4_block5_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_out (Add)         (None, 16, 16, 1024  0           ['conv4_block4_out[0][0]',       \n",
            "                                )                                 'conv4_block5_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_preact_bn (BatchN  (None, 16, 16, 1024  4096       ['conv4_block5_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_preact_relu (Acti  (None, 16, 16, 1024  0          ['conv4_block6_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 16, 16, 256)  262144      ['conv4_block6_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_pad (ZeroPaddin  (None, 18, 18, 256)  0          ['conv4_block6_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 8, 8, 256)    589824      ['conv4_block6_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block6_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 1024)  0           ['conv4_block5_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2D)   (None, 8, 8, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_out (Add)         (None, 8, 8, 1024)   0           ['max_pooling2d_2[0][0]',        \n",
            "                                                                  'conv4_block6_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_preact_bn (BatchN  (None, 8, 8, 1024)  4096        ['conv4_block6_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv5_block1_preact_relu (Acti  (None, 8, 8, 1024)  0           ['conv5_block1_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 8, 8, 512)    524288      ['conv5_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 8, 8, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_pad (ZeroPaddin  (None, 10, 10, 512)  0          ['conv5_block1_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 8, 8, 512)    2359296     ['conv5_block1_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activatio  (None, 8, 8, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2D)   (None, 8, 8, 2048)   2099200     ['conv5_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2D)   (None, 8, 8, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_out (Add)         (None, 8, 8, 2048)   0           ['conv5_block1_0_conv[0][0]',    \n",
            "                                                                  'conv5_block1_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_preact_bn (BatchN  (None, 8, 8, 2048)  8192        ['conv5_block1_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv5_block2_preact_relu (Acti  (None, 8, 8, 2048)  0           ['conv5_block2_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 8, 8, 512)    1048576     ['conv5_block2_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 8, 8, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_pad (ZeroPaddin  (None, 10, 10, 512)  0          ['conv5_block2_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 8, 8, 512)    2359296     ['conv5_block2_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activatio  (None, 8, 8, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2D)   (None, 8, 8, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_out (Add)         (None, 8, 8, 2048)   0           ['conv5_block1_out[0][0]',       \n",
            "                                                                  'conv5_block2_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_preact_bn (BatchN  (None, 8, 8, 2048)  8192        ['conv5_block2_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv5_block3_preact_relu (Acti  (None, 8, 8, 2048)  0           ['conv5_block3_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 8, 8, 512)    1048576     ['conv5_block3_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 8, 8, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_pad (ZeroPaddin  (None, 10, 10, 512)  0          ['conv5_block3_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 8, 8, 512)    2359296     ['conv5_block3_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activatio  (None, 8, 8, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2D)   (None, 8, 8, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_out (Add)         (None, 8, 8, 2048)   0           ['conv5_block2_out[0][0]',       \n",
            "                                                                  'conv5_block3_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " post_bn (BatchNormalization)   (None, 8, 8, 2048)   8192        ['conv5_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " post_relu (Activation)         (None, 8, 8, 2048)   0           ['post_bn[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23,564,800\n",
            "Trainable params: 0\n",
            "Non-trainable params: 23,564,800\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "2022-04-23 16:19:34.962928: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 25165824 exceeds 10% of free system memory.\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
            "                                                                 \n",
            " sequential (Sequential)     (None, 256, 256, 3)       0         \n",
            "                                                                 \n",
            " tf.math.truediv (TFOpLambda  (None, 256, 256, 3)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " tf.math.subtract (TFOpLambd  (None, 256, 256, 3)      0         \n",
            " a)                                                              \n",
            "                                                                 \n",
            " resnet50v2 (Functional)     (None, 8, 8, 2048)        23564800  \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 2048)             0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               524544    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 13)                3341      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24,092,685\n",
            "Trainable params: 527,885\n",
            "Non-trainable params: 23,564,800\n",
            "_________________________________________________________________\n",
            "None\n",
            "Start training\n",
            "Epoch 1/15\n",
            "2022-04-23 16:19:52.311981: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 25165824 exceeds 10% of free system memory.\n",
            "  1/201 [..............................] - ETA: 33:24 - loss: 3.7039 - accuracy: 0.03122022-04-23 16:19:55.211544: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 25165824 exceeds 10% of free system memory.\n",
            "  2/201 [..............................] - ETA: 1:44 - loss: 3.7234 - accuracy: 0.0781 2022-04-23 16:19:55.675280: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 25165824 exceeds 10% of free system memory.\n",
            "  3/201 [..............................] - ETA: 1:36 - loss: 3.6353 - accuracy: 0.10422022-04-23 16:19:56.054852: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 25165824 exceeds 10% of free system memory.\n",
            "201/201 [==============================] - 123s 565ms/step - loss: 2.1315 - accuracy: 0.3277 - val_loss: 1.6056 - val_accuracy: 0.4836\n",
            "Epoch 2/15\n",
            "201/201 [==============================] - 113s 550ms/step - loss: 1.8102 - accuracy: 0.4135 - val_loss: 1.5065 - val_accuracy: 0.5117\n",
            "Epoch 3/15\n",
            "201/201 [==============================] - 105s 510ms/step - loss: 1.7207 - accuracy: 0.4408 - val_loss: 1.4773 - val_accuracy: 0.5201\n",
            "Epoch 4/15\n",
            "201/201 [==============================] - 103s 500ms/step - loss: 1.6670 - accuracy: 0.4586 - val_loss: 1.4673 - val_accuracy: 0.5187\n",
            "Epoch 5/15\n",
            "201/201 [==============================] - 103s 501ms/step - loss: 1.6408 - accuracy: 0.4699 - val_loss: 1.4794 - val_accuracy: 0.5187\n",
            "Epoch 6/15\n",
            "201/201 [==============================] - 104s 507ms/step - loss: 1.5945 - accuracy: 0.4961 - val_loss: 1.4482 - val_accuracy: 0.5285\n",
            "Epoch 7/15\n",
            "201/201 [==============================] - 100s 485ms/step - loss: 1.5507 - accuracy: 0.5011 - val_loss: 1.4404 - val_accuracy: 0.5402\n",
            "Epoch 8/15\n",
            "201/201 [==============================] - 103s 501ms/step - loss: 1.5443 - accuracy: 0.5028 - val_loss: 1.4409 - val_accuracy: 0.5341\n",
            "Epoch 9/15\n",
            "201/201 [==============================] - 103s 502ms/step - loss: 1.5044 - accuracy: 0.5079 - val_loss: 1.4533 - val_accuracy: 0.5327\n",
            "Epoch 10/15\n",
            "201/201 [==============================] - 103s 500ms/step - loss: 1.4876 - accuracy: 0.5248 - val_loss: 1.4354 - val_accuracy: 0.5369\n",
            "Epoch 11/15\n",
            "201/201 [==============================] - 104s 505ms/step - loss: 1.5044 - accuracy: 0.5196 - val_loss: 1.4336 - val_accuracy: 0.5355\n",
            "Epoch 12/15\n",
            "201/201 [==============================] - 101s 490ms/step - loss: 1.4442 - accuracy: 0.5294 - val_loss: 1.4785 - val_accuracy: 0.5397\n",
            "Epoch 13/15\n",
            "201/201 [==============================] - 102s 495ms/step - loss: 1.4496 - accuracy: 0.5368 - val_loss: 1.4735 - val_accuracy: 0.5350\n",
            "Epoch 14/15\n",
            "201/201 [==============================] - 100s 488ms/step - loss: 1.4205 - accuracy: 0.5475 - val_loss: 1.4698 - val_accuracy: 0.5430\n",
            "Epoch 15/15\n",
            "201/201 [==============================] - 101s 493ms/step - loss: 1.4240 - accuracy: 0.5478 - val_loss: 1.4833 - val_accuracy: 0.5430\n",
            "                                  precision    recall  f1-score   support\n",
            "\n",
            "                      Appliances       0.58      0.64      0.61       160\n",
            "               Baby & Kids Stuff       0.38      0.43      0.41       116\n",
            " Clothes, Footwear & Accessories       0.66      0.56      0.61       146\n",
            "            Computers & Software       0.63      0.63      0.63       174\n",
            "           DIY Tools & Materials       0.57      0.53      0.55       153\n",
            "                 Health & Beauty       0.62      0.51      0.56       182\n",
            "                   Home & Garden       0.57      0.61      0.59       270\n",
            "     Music, Films, Books & Games       0.57      0.65      0.61       188\n",
            "    Office Furniture & Equipment       0.55      0.60      0.57       167\n",
            "                     Other Goods       0.33      0.23      0.27       142\n",
            "Phones, Mobile Phones & Telecoms       0.65      0.77      0.71       167\n",
            "        Sports, Leisure & Travel       0.53      0.56      0.54       136\n",
            "          Video Games & Consoles       0.53      0.47      0.50       139\n",
            "\n",
            "                        accuracy                           0.56      2140\n",
            "                       macro avg       0.55      0.55      0.55      2140\n",
            "                    weighted avg       0.56      0.56      0.56      2140\n",
            "\n",
            "Evaluation on model accuracy 0.564018691588785, loss 2.2064242362976074\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "Start tokenising the product name and description\n",
            "Creating a Word2Vec model, dimension 300, pre-train model None\n",
            "Getting index from the embedding model\n",
            "Prepare training, validation and testing data\n",
            "Finish preparing data, shape of X_train (6418, 1458), shape of X_val (1079, 1458), shape of X_test (1057, 1458), shape of y_train (6418, 13), shape of y_val (1079, 13), shape of y_test (1057, 13)\n",
            "Model created\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 1458, 300)         8397600   \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 1456, 48)          43248     \n",
            "                                                                 \n",
            " average_pooling1d (AverageP  (None, 728, 48)          0         \n",
            " ooling1D)                                                       \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 728, 48)           0         \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 726, 24)           3480      \n",
            "                                                                 \n",
            " average_pooling1d_1 (Averag  (None, 363, 24)          0         \n",
            " ePooling1D)                                                     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 8712)              0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8712)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               2230528   \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 13)                3341      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,678,197\n",
            "Trainable params: 2,280,597\n",
            "Non-trainable params: 8,397,600\n",
            "_________________________________________________________________\n",
            "None\n",
            "Start training\n",
            "Epoch 1/50\n",
            "201/201 [==============================] - ETA: 0s - loss: 2.5720 - accuracy: 0.1206tcmalloc: large alloc 2015428608 bytes == 0x564f5aef0000 @  0x7f4175593b6b 0x7f41755b3379 0x7f40945cc257 0x7f4082a5630f 0x7f4082af2cbb 0x7f4082906d97 0x7f4082907600 0x7f4082907708 0x7f408910e41d 0x7f4082c99228 0x7f408f987fbf 0x7f4088f0d6d4 0x7f4088f0e7b1 0x7f408ff02a8f 0x7f4088f08e95 0x7f4088f09873 0x7f4088bd3709 0x7f408f996511 0x7f408860defd 0x7f40883543b3 0x7f40814350b7 0x7f4081458d48 0x564e32996160 0x564e32995ef0 0x564e32a0a123 0x564e32a04a2e 0x564e3299788a 0x564e32a09d30 0x564e32a04a2e 0x564e328d6e2b 0x564e32a06ff1\n",
            "201/201 [==============================] - 10s 39ms/step - loss: 2.5720 - accuracy: 0.1206 - val_loss: 2.4799 - val_accuracy: 0.1603\n",
            "Epoch 2/50\n",
            "199/201 [============================>.] - ETA: 0s - loss: 2.3844 - accuracy: 0.1826tcmalloc: large alloc 2015428608 bytes == 0x564f5aef0000 @  0x7f4175593b6b 0x7f41755b3379 0x7f40945cc257 0x7f4082a5630f 0x7f4082af2cbb 0x7f4082906d97 0x7f4082907600 0x7f4082907708 0x7f408910e41d 0x7f4082c99228 0x7f408f987fbf 0x7f4088f0d6d4 0x7f4088f0e7b1 0x7f408ff02a8f 0x7f4088f08e95 0x7f4088f09873 0x7f4088bd3709 0x7f408f996511 0x7f408860defd 0x7f40883543b3 0x7f40814350b7 0x7f4081458d48 0x564e32996160 0x564e32995ef0 0x564e32a0a123 0x564e32a04a2e 0x564e3299788a 0x564e32a09d30 0x564e32a04a2e 0x564e328d6e2b 0x564e32a06ff1\n",
            "201/201 [==============================] - 7s 36ms/step - loss: 2.3866 - accuracy: 0.1826 - val_loss: 2.2915 - val_accuracy: 0.2215\n",
            "Epoch 3/50\n",
            "201/201 [==============================] - 7s 35ms/step - loss: 2.2442 - accuracy: 0.2515 - val_loss: 2.1513 - val_accuracy: 0.2706\n",
            "Epoch 4/50\n",
            "201/201 [==============================] - 7s 35ms/step - loss: 2.0883 - accuracy: 0.2942 - val_loss: 2.0623 - val_accuracy: 0.3133\n",
            "Epoch 5/50\n",
            "201/201 [==============================] - 7s 34ms/step - loss: 2.0032 - accuracy: 0.3255 - val_loss: 1.9359 - val_accuracy: 0.3679\n",
            "Epoch 6/50\n",
            "201/201 [==============================] - 7s 34ms/step - loss: 1.9311 - accuracy: 0.3546 - val_loss: 1.9537 - val_accuracy: 0.3661\n",
            "Epoch 7/50\n",
            "201/201 [==============================] - 7s 34ms/step - loss: 1.8517 - accuracy: 0.3694 - val_loss: 1.8246 - val_accuracy: 0.3985\n",
            "Epoch 8/50\n",
            "201/201 [==============================] - 7s 34ms/step - loss: 1.7993 - accuracy: 0.3984 - val_loss: 1.7514 - val_accuracy: 0.4300\n",
            "Epoch 9/50\n",
            "201/201 [==============================] - 7s 35ms/step - loss: 1.7646 - accuracy: 0.4149 - val_loss: 1.7960 - val_accuracy: 0.4106\n",
            "Epoch 10/50\n",
            "201/201 [==============================] - 7s 35ms/step - loss: 1.7261 - accuracy: 0.4310 - val_loss: 1.7126 - val_accuracy: 0.4486\n",
            "Epoch 11/50\n",
            "201/201 [==============================] - 7s 36ms/step - loss: 1.7093 - accuracy: 0.4321 - val_loss: 1.6537 - val_accuracy: 0.4597\n",
            "Epoch 12/50\n",
            "201/201 [==============================] - 7s 34ms/step - loss: 1.6832 - accuracy: 0.4501 - val_loss: 1.6533 - val_accuracy: 0.4597\n",
            "Epoch 13/50\n",
            "201/201 [==============================] - 7s 34ms/step - loss: 1.8542 - accuracy: 0.4467 - val_loss: 1.6473 - val_accuracy: 0.4690\n",
            "Epoch 14/50\n",
            "201/201 [==============================] - 7s 35ms/step - loss: 1.7601 - accuracy: 0.4553 - val_loss: 1.6297 - val_accuracy: 0.4838\n",
            "Epoch 15/50\n",
            "201/201 [==============================] - 7s 34ms/step - loss: 1.6134 - accuracy: 0.4610 - val_loss: 1.6244 - val_accuracy: 0.4829\n",
            "Epoch 16/50\n",
            "201/201 [==============================] - 7s 35ms/step - loss: 1.6233 - accuracy: 0.4690 - val_loss: 1.6535 - val_accuracy: 0.4634\n",
            "Epoch 17/50\n",
            "201/201 [==============================] - 7s 35ms/step - loss: 1.6849 - accuracy: 0.4744 - val_loss: 1.6000 - val_accuracy: 0.4921\n",
            "Epoch 18/50\n",
            "201/201 [==============================] - 7s 36ms/step - loss: 1.6274 - accuracy: 0.4872 - val_loss: 1.5954 - val_accuracy: 0.4884\n",
            "Epoch 19/50\n",
            "201/201 [==============================] - 7s 35ms/step - loss: 1.6703 - accuracy: 0.4914 - val_loss: 1.5877 - val_accuracy: 0.4875\n",
            "Epoch 20/50\n",
            "201/201 [==============================] - 7s 34ms/step - loss: 1.5413 - accuracy: 0.5028 - val_loss: 1.5952 - val_accuracy: 0.4977\n",
            "Epoch 21/50\n",
            "201/201 [==============================] - 7s 35ms/step - loss: 1.5902 - accuracy: 0.4911 - val_loss: 1.6173 - val_accuracy: 0.4847\n",
            "Epoch 22/50\n",
            "201/201 [==============================] - 7s 34ms/step - loss: 1.5121 - accuracy: 0.5005 - val_loss: 1.5495 - val_accuracy: 0.5070\n",
            "Epoch 23/50\n",
            "201/201 [==============================] - 7s 35ms/step - loss: 1.5084 - accuracy: 0.5062 - val_loss: 1.5839 - val_accuracy: 0.4801\n",
            "Epoch 24/50\n",
            "201/201 [==============================] - 7s 35ms/step - loss: 1.5627 - accuracy: 0.5056 - val_loss: 1.5534 - val_accuracy: 0.5190\n",
            "Epoch 25/50\n",
            "201/201 [==============================] - 7s 36ms/step - loss: 1.5228 - accuracy: 0.5176 - val_loss: 1.5963 - val_accuracy: 0.5060\n",
            "Epoch 26/50\n",
            "201/201 [==============================] - 7s 33ms/step - loss: 1.6738 - accuracy: 0.5125 - val_loss: 1.5553 - val_accuracy: 0.4986\n",
            "Epoch 27/50\n",
            "201/201 [==============================] - 7s 36ms/step - loss: 1.4630 - accuracy: 0.5243 - val_loss: 1.5787 - val_accuracy: 0.4819\n",
            "Epoch 28/50\n",
            "201/201 [==============================] - 7s 36ms/step - loss: 1.5015 - accuracy: 0.5254 - val_loss: 1.5491 - val_accuracy: 0.5125\n",
            "Epoch 29/50\n",
            "201/201 [==============================] - 7s 34ms/step - loss: 1.4506 - accuracy: 0.5242 - val_loss: 1.5641 - val_accuracy: 0.5134\n",
            "Epoch 30/50\n",
            "201/201 [==============================] - 7s 34ms/step - loss: 1.4377 - accuracy: 0.5282 - val_loss: 1.5842 - val_accuracy: 0.4968\n",
            "Epoch 31/50\n",
            "201/201 [==============================] - 7s 33ms/step - loss: 1.4374 - accuracy: 0.5263 - val_loss: 1.6158 - val_accuracy: 0.5042\n",
            "Epoch 32/50\n",
            "201/201 [==============================] - 7s 34ms/step - loss: 1.4281 - accuracy: 0.5304 - val_loss: 1.5654 - val_accuracy: 0.5209\n",
            "Epoch 33/50\n",
            "201/201 [==============================] - 7s 34ms/step - loss: 1.4086 - accuracy: 0.5385 - val_loss: 1.5706 - val_accuracy: 0.5125\n",
            "Epoch 34/50\n",
            "201/201 [==============================] - 7s 34ms/step - loss: 1.4116 - accuracy: 0.5319 - val_loss: 1.5524 - val_accuracy: 0.5005\n",
            "Epoch 35/50\n",
            "201/201 [==============================] - 7s 34ms/step - loss: 1.4955 - accuracy: 0.5337 - val_loss: 1.5499 - val_accuracy: 0.4977\n",
            "Epoch 36/50\n",
            "201/201 [==============================] - 7s 35ms/step - loss: 1.4010 - accuracy: 0.5432 - val_loss: 1.5404 - val_accuracy: 0.5116\n",
            "Epoch 37/50\n",
            "201/201 [==============================] - 7s 34ms/step - loss: 1.3954 - accuracy: 0.5432 - val_loss: 1.5244 - val_accuracy: 0.5079\n",
            "Epoch 38/50\n",
            "201/201 [==============================] - 7s 34ms/step - loss: 1.4725 - accuracy: 0.5360 - val_loss: 1.5454 - val_accuracy: 0.5014\n",
            "Epoch 39/50\n",
            "201/201 [==============================] - 7s 35ms/step - loss: 1.3858 - accuracy: 0.5471 - val_loss: 1.5265 - val_accuracy: 0.5209\n",
            "Epoch 40/50\n",
            "201/201 [==============================] - 7s 35ms/step - loss: 1.4181 - accuracy: 0.5471 - val_loss: 1.5581 - val_accuracy: 0.5125\n",
            "Epoch 41/50\n",
            "201/201 [==============================] - 7s 33ms/step - loss: 1.3858 - accuracy: 0.5471 - val_loss: 1.5392 - val_accuracy: 0.5116\n",
            "Epoch 42/50\n",
            "201/201 [==============================] - 7s 35ms/step - loss: 1.3893 - accuracy: 0.5503 - val_loss: 1.5474 - val_accuracy: 0.5236\n",
            "Epoch 43/50\n",
            "201/201 [==============================] - 7s 34ms/step - loss: 1.3724 - accuracy: 0.5595 - val_loss: 1.5490 - val_accuracy: 0.5042\n",
            "Epoch 44/50\n",
            "201/201 [==============================] - 7s 35ms/step - loss: 1.3731 - accuracy: 0.5488 - val_loss: 1.5444 - val_accuracy: 0.5171\n",
            "Epoch 45/50\n",
            "201/201 [==============================] - 7s 34ms/step - loss: 1.3753 - accuracy: 0.5466 - val_loss: 1.5210 - val_accuracy: 0.5218\n",
            "Epoch 46/50\n",
            "201/201 [==============================] - 7s 36ms/step - loss: 1.3546 - accuracy: 0.5597 - val_loss: 1.5137 - val_accuracy: 0.5097\n",
            "Epoch 47/50\n",
            "201/201 [==============================] - 7s 34ms/step - loss: 1.3588 - accuracy: 0.5564 - val_loss: 1.5571 - val_accuracy: 0.5209\n",
            "Epoch 48/50\n",
            "201/201 [==============================] - 7s 34ms/step - loss: 1.3498 - accuracy: 0.5547 - val_loss: 1.5612 - val_accuracy: 0.5079\n",
            "Epoch 49/50\n",
            "201/201 [==============================] - 7s 35ms/step - loss: 1.3832 - accuracy: 0.5591 - val_loss: 1.5312 - val_accuracy: 0.5209\n",
            "Epoch 50/50\n",
            "201/201 [==============================] - 7s 35ms/step - loss: 1.3736 - accuracy: 0.5559 - val_loss: 1.5252 - val_accuracy: 0.5264\n",
            "Finish training\n",
            "                                  precision    recall  f1-score   support\n",
            "\n",
            "                      Appliances       0.50      0.51      0.50        79\n",
            "               Baby & Kids Stuff       0.68      0.28      0.40        68\n",
            " Clothes, Footwear & Accessories       0.61      0.57      0.59        68\n",
            "            Computers & Software       0.72      0.71      0.72        89\n",
            "           DIY Tools & Materials       0.17      0.48      0.25        88\n",
            "                 Health & Beauty       0.35      0.47      0.40        88\n",
            "                   Home & Garden       0.64      0.51      0.56       120\n",
            "     Music, Films, Books & Games       0.79      0.56      0.65        98\n",
            "    Office Furniture & Equipment       0.88      0.64      0.74        94\n",
            "                     Other Goods       0.19      0.16      0.18        73\n",
            "Phones, Mobile Phones & Telecoms       0.80      0.64      0.71        64\n",
            "        Sports, Leisure & Travel       0.58      0.31      0.40        58\n",
            "          Video Games & Consoles       0.89      0.69      0.77        70\n",
            "\n",
            "                        accuracy                           0.51      1057\n",
            "                       macro avg       0.60      0.50      0.53      1057\n",
            "                    weighted avg       0.60      0.51      0.54      1057\n",
            "\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tensorboard dev upload --logdir ./logs/image_model \\\n",
        "  --name \"RestNetV50 based CNN image classification model\" \\\n",
        "  --description \"Training results for CNN models\" \\\n",
        "  --one_shot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBN1iYsFJc6C",
        "outputId": "8d69bc11-7968-42aa-9994-517657c7b875"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "New experiment created. View your TensorBoard at: https://tensorboard.dev/experiment/Ze8GNeW5T2yhepr8YKgnWA/\n",
            "\n",
            "\u001b[1m[2022-04-23T17:32:31]\u001b[0m Started scanning logdir.\n",
            "\u001b[1m[2022-04-23T17:32:41]\u001b[0m Total uploaded: 90 scalars, 4112 tensors (2.9 MB), 1 binary objects (468.2 kB)\n",
            "\u001b[1m[2022-04-23T17:32:41]\u001b[0m Done scanning logdir.\n",
            "\n",
            "\n",
            "Done. View your TensorBoard at https://tensorboard.dev/experiment/Ze8GNeW5T2yhepr8YKgnWA/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tensorboard dev upload --logdir ./logs/text_model \\\n",
        "  --name \"CNN text classification model\" \\\n",
        "  --description \"Training results for CNN models\" \\\n",
        "  --one_shot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZM6gMJAeg2x",
        "outputId": "556583a5-7081-4390-e123-bebc74d72ceb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "New experiment created. View your TensorBoard at: https://tensorboard.dev/experiment/9u1q6KkzTzaJm5I6fVwO7Q/\n",
            "\n",
            "\u001b[1m[2022-04-23T17:35:04]\u001b[0m Started scanning logdir.\n",
            "\u001b[1m[2022-04-23T17:35:07]\u001b[0m Total uploaded: 300 scalars, 452 tensors (323.0 kB), 1 binary objects (85.8 kB)\n",
            "\u001b[1m[2022-04-23T17:35:07]\u001b[0m Done scanning logdir.\n",
            "\n",
            "\n",
            "Done. View your TensorBoard at https://tensorboard.dev/experiment/9u1q6KkzTzaJm5I6fVwO7Q/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pNmYqxA0e8jd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}